---
title: "Faber 文章：传统机器学习拟合 DFT 性质"
comments: True
permalink: /post/Faber-Repetition/
categories: [基础量子化学, 机器学习]
excerpt: "Faber (JCTC 2017) 使用了许多特征方法与 ML 方法测评，认为从模型误差上，ML 要优于杂化 DFA 误差。不论这么说是否夸大了 ML 的能力，是否真的对我们微观世界的认识有所帮助与启迪；但这项工作连同 Gilmer (ICML 2017)，我认为存在改变现有的理论化学中理论计算方向，以及计算化学工具的发展平衡的可能。"
keywords: Faber, Gilmer, 机器学习, Machine Learning, 密度泛函, DFT, 量子化学, Quantum Chemistry
---

{% include toc %}

# 前言

## 缘起

这是我在研究生的跨一级专业选修课上的作业节选。课上的要求是阅读一份 2017 年的主流机器学习杂志的文章。我当时看到了 Gilmer *et al.* ([ICML 2017](http://proceedings.mlr.press/v70/gilmer17a.html)) 的文章（Neural Message Passing for Quantum Chemistry），发现其中的内容让我感到非常亲切。这篇文章的工作从目标上来说其实很清楚，就是将分子信息输入到 ML（Machine Learning）中，经过监督学习后得到分子的各种性质。

但是这篇文章的工作使用的是我很难理解的图模型的深度网络，从技术上对我来说也很难实现。当我看到 Gilmer *et al.* 的作者们同时还与 O. A. v. Lilienfeld 组发了另一篇文章 Faber *et al.* ([JCTC 2017](https://dx.doi.org/10.1021/acs.jctc.7b00577)) 时，我打算先从这篇相对来说简单一些的文章入手，了解机器学习是如何参与微观的理论化学研究。

## 文章重复

在这篇博客中，我会简单地叙述我所理解的 Faber *et al.* 的工作内容，给出其中部分结果的实现代码，并作非常简单的评价。

所有重复出的工作仅仅是 Faber *et al.* 的 Table 3 中的三行。但我想这两行的重复使得我有信心，让我相信在可见的未来彻底理解他们的这份工作。

![Fig 1. 你可以看看我重复了多少工作 →_→](/images/Posts/2018-01-30-Faber_Repetition/fig1.png)
<center>
Fig 1. 你可以看看我重复了多少工作 →.→
</center>

# 特征工程

我认为 Faber *et al.* 等人最重要的工作是他们的特征工程；不同于 Gilmer *et al.*，他们主要的目的是对算法的改进。

# 评价

免责声明：这一节是大话吹笔时间。一派胡话。（认真脸 = =）

## 关于拟合 DFT 的感想

我曾经一位室友是药学-有机方向。我问过他，说如果现在有两种 DFT，
1. 一种比较接近真实泛函（我们不妨假定真实泛函存在可以套用到 Kohn-Sham 解的简单形式），它算啥都不差，但也不算太准；
2. 另一种偏离真实泛函比较远，但它算药物分子的结果会更好；

两个计算代价啊啥的都一样。你要哪一种？

他当然毫不犹豫地选后面一个。

现在我能了解到的情况是，类似于 PBE 的更接近于真实的泛函在化学中未必比 M06 系列泛函更受到欢迎<!--注释：对于这里的“更接近于”，不同的人显然会有不同的评价方式。这里引用的是 Predew 等人的评述方式（Medvedev *et al.*, [Science 2017](https://dx.doi.org/10.1126/science.aah5975)）。Predew 的著名工作之一是开发无经验参数泛函，这些泛函相对于其它流行 DFT 近似而言通常会满足更多泛函限制条件。在前述链接文章中，作者的数据表明 M06 系列泛函尽管能量表现不错，但电子密度表现并不太好；是偏离真实泛函的表现之一。-->。M06 系列泛函不算是很准确的泛函；之所以其表现良好，可能主要的原因是其开发原理与大多数泛函不太一样。它的泛函中有大量参数（约 50 个），这些参数由实验数据进行拟合，而拟合范围是大量的化学分子与反应。因此，泛函在这些分子、这类反应下的表现通常都好于其它泛函不少；而化学家最关心的大多也就在这些分子、这类反应之间。而 PBE 泛函则是物理与化学领域中都使用的泛函，满足了更多的泛函限制条件，看起来更接近真实泛函；但计算结果却经常劣势于 M06 系列。

我作为理论化学的学生，也许会理所当然地认为，第 1 条路径更好。即使使用类似于 PBE 的泛函会牺牲一些计算准确度，但我们可以一步一步地对泛函引入限制条件来改善泛函，使得这个泛函也可以越来越准确——既然 Schrödinger 方程原则上能被无穷精度地求解，这种泛函也应当存在。而反过来说，用一个有大量参数，但模型本身较为一般的泛函形式进行拟合，不是一个很好的途径——毕竟拟合过程中，泛函模型误差也许不大，但被拟合的数据本身也有着误差；这两个误差叠加也许凑巧得到不错的结果，但这两个误差都是难以从理论上修正的，并且作为误差还有叠加的可能。这是为什么我也许会觉得，开发新泛函的思路最好是能沿着泛函限制条件。

但是第 2 条路径相信是更为大家接受的。毕竟，在可见的未来，在相同的计算量下，第 2 类泛函即使会受到批评，但其实对于我们关心的分子表现稳定且良好，我们为何不用呢？

这个问题看起来跟这篇文章没有关系，但是我认为如果接受第 2 条路径的人，不妨考虑一下 ML 的结果。

## 直接 ML 计算化学性质的感想

在 DFT 上套以 ML，我了解的是现在至少有两种策略。一种是直接用 ML 做泛函（Brockherde *et al.*, [*Nat. Commun.* 2017](https://dx.doi.org/10.1038/s41467-017-00839-3)），另一种就是这篇文章的做法，即将 DFT 结果用 ML 拟合。这里讲的是后一种。至于是否使用深度网络，还是使用较为原始的机器学习，在讨论当前这个问题上不是很重要。

如果我选择了上面一节提到的第 2 条路径，作为化学工作者，我想我一定会犹豫着是否要用 ML 替代 DFT 计算。DFT 显然是由学界所承认的方法，尽管其计算量很大，作为模型的精度也未必好于拟合区间里的 ML。DFT 之所以被学界所承认，我想是因为它具有清楚的物理意义，有 Hohenberg-Kohn 定理托底；而这是 ML 所不具备的。

举一个很不恰当的例子。如果现在有一段动画，想要表达钢琴家（Kousei）与小提琴家（Kaori）激情澎湃的表演；然而制作公司（A-1 Pictures）没有足够经费（chéngyì）充分表现这个镜头。最中规中矩的方式是仍然绘制两人的动图，但会把手部动作切掉不很多，只留下头部的陶醉神情；另一种则是突破常规，在很少的几秒之内充分绘制手部动作，但剩下的几秒用静止立绘（PPT）替代。两种都不完美，但也可以一定程度地让观众感受到动画的魅力。我觉得 DFT 近似更像前者，而 ML 更像后者。

（我觉得我要被四月迷寄刀片了 ↗﹏↖ 况且 Sony 亲儿子；外加作为不懂动画的人，上面的话多少有些曲解监督分镜的初衷）

回到话题。DFT 本身有物理含义，但如果一些 DFT 近似却舍弃了大部分物理含义给它的限制，那么我们就不应当认为这种 DFT 是基于物理的，而是基于工业应用的。这与 ML 解决化学性质问题几乎是一致的，只是两者的模型名称不同而已。我们其实不必拘泥于 DFT 近似的模型而直接使用更高效而不失效率的 ML；就像几张漂亮的立绘和几秒华丽的动画就可以达到甚至超脱于平平凡凡的动作，为何不用？

## 对于 DFT 近似未来的担忧

可能在很长一段时间里，ML 无法比 DFT 近似更好。毕竟拟合集的误差在那里，外加 ML 方法解决本应可以用有严格物理基础的化学问题恐怕会在短期内不为大家很快接受；但这恐怕是暂时的。拟合集误差只会越来越小，ML 模型误差只会越来越小；这种情况下，再顽固的人都会动摇。那么我们是否要继续研究 DFT 呢？

研究 DFT 也许会有两种目的，效率与理论本身的意义。

DFT 本身就是作为与 HF 计算量级相同，但要远适合现实计算的理论基础。如今大多数中等体系都已经接受了 DFT 计算量，所以 DFT 才会走入大家的视野。

然而绝大多数 DFT 近似都使用了经验参数的拟合，或多或少。即使是无经验参数的 DFT 近似，它也多少包含一些设计上经验的考虑。如果我们把 DFT 近似当作一种模型原理，这和 ML 有什么区别？只是 DFT 近似的泛函集不需要很多，只要构造比较合理，寥寥几个参数就可以得到一个不错的泛函；ML 则是少则几百，多则上万的参数，但还是算得快。在将来，如果无视了分子计算中的容斥规则的话，甚至可以让 ML 的计算量线性地随分子大小而增大（就如 [Gilmer *et al.*](http://proceedings.mlr.press/v70/gilmer17a.html) 文中所述的 Tower8 方法，也许用几个神经网络将分立的隐含层接起来就可以降低计算量）。在这个时代，哪个会发展得更好，一目了然。为了计算精度而设计的 DFT 近似恐怕会陷入困境。

但是如果将 DFT 当作理论来看的话，就会看到另一种风景。最近的一份工作中（Su *et al.*, [PNAS 2018](https://dx.doi.org/10.1073/pnas.1713047115)），作者提到了一类引入虚轨道的非自洽 DFT 近似（xDH）在一些原子与离子的能量与密度性质结果均好于<u>所有</u>杂化泛函。从我的角度和我现在的理解来看，尽管这类泛函大多也有经验参数的成分，但是它对 DFT 近似的模型的改变和结果的优势已经足以让我们去关注后面可能发掘这种模型的物理含义；并且这种认识有希望帮助我们对于我们的目标——终极的泛函的理解更加接近于真实。

不过既然我觉得，尽管 DFT 曾经在千禧年前后有巨大的发展，将来的 DFT 理论学者可能随着 DFT 近似的衰弱而越来越孤独。即使如此，如果真的能找到这样一个精确泛函的话，我想 Hohenberg-Kohn 会很开心——我相信他们一开始没有觉得这个理论会如此有生命力。我也觉得如果我们看到了他们无法看到的精确泛函，他们一定在天堂吓一跳。

# 未尽

1. 这篇博文不管是工作，还是观点，大多数都是独立完成；因此希望大家如果看到不合适的说辞，不要联想到其他人。

2. 在上这门课之前，我算是不会 Python，不懂机器学习的人；对于 DFT 近似其实是一知半解，Python 之前只用过 FORTRAN。说实话还有太多的东西没有学习。大家可以批评我的懒惰，但希望在对术语或概念的理解上，稍稍宽容一些。

3. 这门课程大约占用平时学习时间的约 1/3，这包括了其它课程、以及在课题组工作的时间。说实话这个学期在课题上没有很好的进展。因此非常感谢导师对我在这段时间的宽容。也感谢师兄弟（姐妹）的这段时间的鼓励、支持和批评。之后恐怕会很少再碰这个话题，但我还是想持续关注。当然，如果不是这门课程，我想以我半吊子的性格，不会想尝试认真地对待这个或许很新的领域；因此我也很感谢能上到这门课。

4. 正因为目前不会使用 TensorFlow，现在能做的重复工作也不超过这篇文章了。我会在可能的情况下再尽力尝试重复 Gilmer *et al.* ([ICML 2017](http://proceedings.mlr.press/v70/gilmer17a.html)) 的文章。最近看到的与这篇文章相关的代码是在 [Microsoft/gated-graph-neural-network-samples](https://github.com/Microsoft/gated-graph-neural-network-samples)，此代码现在仍然在活跃地更新，但我认为这份代码没有真正直接地重复 Gilmer *et al.* 的文章。希望大家能期待我下一篇此话题的博客。

# 改动日志

* 2018-01-30 创建网页
* 2018-02-15 初稿
