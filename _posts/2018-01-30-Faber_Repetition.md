---
title: "Faber 文章：机器学习拟合 DFT 性质"
comments: True
permalink: /post/Faber-Repetition/
categories: [基础量子化学, 机器学习]
excerpt: "Faber (JCTC 2017) 使用了许多特征方法与 ML 方法测评，认为从模型误差上，ML 要优于杂化 DFA 误差。不论这么说是否夸大了 ML 的能力，是否真的对我们微观世界的认识有所帮助与启迪；但这项工作连同 Gilmer (ICML 2017)，我认为存在改变现有的理论化学中理论计算方向，以及计算化学工具的发展平衡的可能。"
keywords: Faber, Gilmer, 机器学习, Machine Learning, 密度泛函, DFT, 量子化学, Quantum Chemistry
---

{% include toc %}

# 前言

## 缘起

这是我在研究生的跨一级专业选修课上的作业节选。课上的要求是阅读一份 2017 年的主流机器学习杂志的文章。我当时看到了 Gilmer *et al.* ([ICML 2017](http://proceedings.mlr.press/v70/gilmer17a.html)) 的文章（Neural Message Passing for Quantum Chemistry），发现其中的内容让我感到非常亲切。这篇文章的工作从目标上来说其实很清楚，就是将分子信息输入到 ML（Machine Learning）中，经过监督学习后得到分子的各种性质。

![Fig 0. Gilmer Cover](/images/Posts/2018-01-30-Faber_Repetition/fig0.png)
<center>
Fig 0. Gilmer 文章封面图片。<br>这里的红色、蓝色随着信息传递次数增加而逐渐延伸，应当是表明了在神经网络信息传递的过程中，这两个原子作为节点包含的信息沿着化学键作为边而延伸。 <p></p>
</center>

但是这篇文章的工作使用的是我很难理解的图模型的深度网络，从技术上对我来说也很难实现。当我看到 Gilmer *et al.* 的作者们同时还与 O. A. v. Lilienfeld 组发了另一篇文章 Faber *et al.* ([JCTC 2017](https://dx.doi.org/10.1021/acs.jctc.7b00577)) 时，我打算先从这篇相对来说简单一些的文章入手，了解机器学习是如何参与微观的理论化学研究。这篇文章的大部分方法都使用了比较传统的机器学习方法，即除开深度学习的 ML。

## 文章重复

在这篇博客中，我会简单地叙述我所理解的 Faber *et al.* 的工作内容，给出其中部分结果的实现代码，并作非常简单的评价。

机器学习在实践中通常有三个问题需要解决：特征工程、数据集与学习方法。

Faber *et al.* 使用的学习方法，除了深度学习之外，一共有四种，分别是 Bayesian Ridge Regression，Elastic Net，Random Forest，Kernel Ridge Regression。其中，前两种我理解为带有不同类型惩罚函数的线性拟合模型；第四种我理解为在误差函数中引入了惩罚项，因而在核中也引入了惩罚参数的无参数拟合，它很像一种加权平均，只是权由核与被测试的输入向量所共同确定。Random Forest 作为回归方法我现在还不理解。

关于数据集的问题，将会在下一节的“关于文章标题”叙述。而特征工程后面会详细叙述。

所有重复出的工作仅仅是 Faber *et al.* 的 Table 3 中的三行。但我想这两行的重复使得我有信心，让我相信在可见的未来彻底理解他们的这份工作。

![Fig 1. 你可以看看我重复了多少工作 →_→](/images/Posts/2018-01-30-Faber_Repetition/fig1.png)
<center>
Fig 1. 你可以看看我重复了多少工作 →.→
</center>

# 关于文章标题

## 棒读标题

> Prediction Errors of Molecular Machine Learning Models Lower than Hybrid DFT Error
>
> 机器学习模型的<u>预测</u>误差小于杂化泛函误差

这个标题很容易引起误解。这里不可以理解为

> 机器学习模型的误差小于杂化泛函误差

## 误差的标杆

下面一副图是我对于误差的说法：

![Fig 2. 误差图](/images/Posts/2018-01-30-Faber_Repetition/fig2.png)
<center>
Fig 2. 误差比较图<br>其中，误差由上到下逐渐递增。 <p></p>
</center>

上图中，
* `Exact` 表示的是这个分子的真实性质，是可以被严格用 Schrödinger 求解的结果；只是精确地求解不可能。
* `Experiment` 表示的是这个分子的实验结果；这个结果可以是用化学或物理实验得到的，也可以是通过目前公认的最优秀的近似方法（例如 G$n$ 方法、有限基组 Full-CI、CCSDTQ 等方法）。这个方法的误差通常认为在 1 kCal/mol 左右；也是上图橙色涂块中表示的部分。
* `DFT` 表示目前流行的密度泛函结果；在现在的例子中，它与作为 `Dataset` 的误差是一样的，均是 [B3LYP](https://dx.doi.org/10.1063/1.464913) 误差。
* `MPNN` 是一类 ML 模型，它目前的拟合集 `Dataset` 即为 `DFT`（B3LYP）。如果我们把 `MPNN` 换作其他 ML 模型也是一样的。

我们可以说，ML 作为模型本身的误差，即 `ML Prediction Error`，是基于假定数据集为真值下的误差。这也许很小，甚至小于 `Chemical Accuracy`；但由于拟合数据集的误差偏大，因此它实际上的误差 `ML Error` 预期不应低于 `DFT Error`。

这种状况相信还会维持很长一段时间，因为目前没有办法稳定地获得大量的化学或物理实验数据，特别是对于不稳定分子或者过渡态分子；同时，现有高精度计算的计算量级太大，也无法承受过大过多的分子。所以，现在的所有 ML 方法其实无法得到很好的结果。然而，如果实验方法也在进步的话，ML 对于模型预测精度的提升不会白费；总有一天两者可以相交。所以显然，这两者在化学领域里都是值得发展的。

## “没有噪音”的数据集

不少监督学习的 ML 任务都有对数据集去噪的目的在那里。那最简单的线性回归作为例子，我们可以想象，之所以我们会在线性回归中引入 $L_2$ 惩罚，就是因为我们假定了数据集的噪声以一定的 Gaussian 函数分布，并且假定拟合系数向量也以一定的 Gaussian 函数分布；这些噪声在通常的 ML 任务里作为超参数出现。

然而，现在的例子会是一种很有意思的例子。既然 [QM9 数据集](http://quantum-machine.org/datasets/)的所有性质都是由 B3LYP 计算而得，那么原则上，数据集的目标值的误差不过应该是机器精度导致的误差。即使 B3LYP 并不代表真正的物理规律，但它本身也可以看作是一个严格的数学规律。那么我想，线性回归在这里应用的<u>前提就不成立</u>了。我不太清楚对于其它 ML 模型是否也如此。

## 被拟合的性质

QM9 中提供了至少 13 种作为目标的性质结果。其中确实有一些重要的性质，譬如热力学数值、偶极矩、振动频率、恒容热容等。然而，其中的部分性质我比较担心没有合理的实验意义。譬如 HOMO 与 LUMO 值，尽管现在已经有许多人将它们看作分子电离与亲和能的表现，但关于这些问题现在我认为还在讨论当中（可以参考 Cohen *et al.*, [Chem. Rev. 2012](https://dx.doi.org/10.1021/cr200107z) 的 5.3 节）；并且目前的杂化泛函的 HOMO 与 LUMO，包括它们的差 Band Gap 的表现非常不好（可以参考 Su and Xu, [WIREs Comput Mol Sci 2016](https://dx.doi.org/10.1002/wcms.1274) 的 Fractional Charge Behaviors Of Doubly Hybrid Functionals 一节）。

另一个性质，即电子云平均半径 $\langle \boldsymbol R^2 \rangle$，其实是没有很好的实验意义。

## 杂化 DFT 本身的问题

如果要让 ML 面向实用的话，我们必须知道被拟合的数据的误差到底在哪里。QM9 的数据来源是作为杂化泛函的 B3LYP。最近的几篇比较有影响力的对于 DFT 近似的回顾文章会是 Cohen *et al.*, [Chem. Rev. 2012](https://dx.doi.org/10.1021/cr200107z) 与 Medvedev *et al.*, [Science 2017](https://dx.doi.org/10.1126/science.aah5975)，等等，还有许多我不了解的。比较明显的几个问题是，一般的 DFT 在最简单的模型体系 H<sub>2</sub> 或其正离子的解离曲线上会有严重偏差，表明其解离性质或者过渡态性质令人担忧；简并体系计算困难，这是大多数不包含 Multi-Reference 方法共有的问题；许多泛函的能量表现良好但电子云密度分布无法准确给出，意味着与电子云有关的偶极、静电效应或与分子梯度有关的频率、结构优化、势能面等性质可能会有问题。这些问题也许只是杂化泛函的冰山一角。

## 数据集的分布

QM9 数据集的分子构成方式是由 [GDB-17 分子集](https://dx.doi.org/10.1021/ci300415d)中抽取所有不多于 9 个第二周期原子而得到，且只包含 C, H, O, N, F 原子；GDB-17 分子集构成的方式似乎完全是图论的规则。因此，我觉得 QM9 分子集是“不挑食”的分子集，没有人为地依靠化学的直觉、或者因为对结果的表现不好而忽略哪些分子。即使有一些分子无法被纳入训练，Faber *et al.* 也能说出明确的原因指出在哪一步要将一些分子剔除训练。

然而，这不代表不多于 9 个第二周期原子的分子构成的“化学空间”被充分地采样了。QM9 数据集分子的坐标的求取方式是在 B3LYP 下进行构型优化。因此，我们只得到了相对来说稳定的分子（在 B3LYP 方法下，所有分子的构型都在势函数的极小值）。因此，这个分子集从构成上就无法给出过渡态分子性质，即用 Faber *et al.* 文章的方法恐怕无法预测出合理的化学反应性质，譬如反应活性、反应路径等等。

# 代码

## 我提供的代码

这部分工作的代码可以到 [ajz34/ML_Course_Code_Report](https://github.com/ajz34/ML_Course_Code_Report) 上查看。其中的 `Faber_Code` 是与这篇博文有关的代码，较为详细的代码解释可以见 `tex` 文件夹下的 pdf 文档。

其中的一些网页文档可能会无法打开。一般来说，网页文档等同于对应同名 Jupyter Notebook 文档，因此安装一个 Anaconda 就应该可以打开这些文档；或者直接在 github 上查看这些 Jupyter Notebook。所有文件格式是 Unix 格式，因此请不要用 Windows 下的 Notepad 打开这些文档。TeX 文档则使用 TexLive 2017 的 xelatex 编译。

除了 `Faber_Code/01-Feature_Vector` 外，其它代码多少因为路径问题，需要修改一下，并且要下载与解压下述作者提供的文件才能跑起来。

之所以 KRR 的结果没能给出来，我认为不是因为代码没有写正确，而是 KRR 确实很耗时。同时它占用很大的内存——作为不大的特征向量，CM 最大会去 200 GB 内存。在我对 CPU 的监控过程中，发现 sklearn 的 KRR 大多数时候没有在并行计算。

## 作者提供的补充材料

上面的 Repo 不能真正地给出正确结果。如果要使上面 Repo 中的 `Faber_Code/02-Repeat_Table3` 跑起来的话，需要下载 Faber *et al.* 在 Supporting Information 中提供的 [Google Drive 文件](https://drive.google.com/open?id=0Bzn36Iqm8hZscHFJcVh5aC1mZFU)；以及 QM9 数据集在 [figshare](https://figshare.com/collections/Quantum_chemistry_structures_and_properties_of_134_kilo_molecules/978904) 上的分享。对于无法爬墙的童鞋，请左转移步到下述[百度网盘](https://pan.baidu.com/s/1ec0Tci)。

# 特征工程

下面尝试开始叙述 Faber *et al.* 的工作内容。

我认为 Faber *et al.* 等人最重要的工作是他们的特征工程；不同于 Gilmer *et al.* 主要的目的是对算法的改进。在这篇文章里，大多数特征工程的方法都由 O. A. v. Lilienfeld 组提出。下面首先会叙述一些我能理解的他们对分子进行特征向量化的过程。我现在重复出的两种特征向量是 CM 与 BoB；其它方法还没有进行过尝试，因此不保证叙述的正确性。

特征工程简单讲来，就是从研究对象出发，得到 ML 训练的输入。它通常都是一维向量，然而现在的深度学习中（例如 Gilmer *et al.* 的基于图的神经网络的 MPNN 模型），这种输入可以是作为节点信息的一维向量与作为边信息的二维矩阵。

## CM

CM (<u>C</u>oulomb <u>M</u>atrix) 特征方法的原始文献为 Rupp *et al.* ([PRL 2012](https://dx.doi.org/10.1103/PhysRevLett.108.058301))。Faber *et al.* 构建特征向量的方式其实不同于 Rupp *et al.*。

### CM 矩阵构造

CM 本身是一个二维矩阵。它的每一个行或列代表一个原子；矩阵的构成很简单，就是每两个原子之间的 Coulomb 经典互斥。不过这里还照顾到矩阵对角线上实际不存在的原子自斥，因此给出了下述的特征矩阵：

$$
\begin{align}
  M_{ij} =
  \left\{
  \begin{aligned}
    0.5 Z_I^{2.4} \quad & \mathrm{for} \quad I = J \,; \\
    \frac{Z_I Z_J}{\vert \boldsymbol R_I - \boldsymbol R_J \vert} \quad & \mathrm{for} \quad I \neq J \,.
  \end{aligned}
  \right.
\end{align}
$$

其中，$\boldsymbol{\mathrm{M}}$ 代表 CM 矩阵；$Z_I$ 代表第 $I$ 个原子的电荷，以 a.u. 为单位；$\boldsymbol R_I$ 代表第 I 个原子的位置，以 a.u. 或 Å 为单位。

你可以简单地认为，CM 矩阵的非对角元是距离矩阵在原子对电荷加权下的倒数矩阵。

### CM 向量处理

由于不同分子将会有不同大小的 CM 矩阵，因此，额外的补零工作是必要的。同时，由于通常输入到 ML 的特征向量是一维向量，因而还需要进行压平。对于相同的 CM 矩阵，不同的特征向量处理方式会得到不同的结果。

#### Rupp *et al.* 的做法

1. 对 CM 矩阵求取其本征值，将这些本征值组合起来，构成本征值向量 $\boldsymbol \epsilon$（注意不是本征向量）；
2. 将这些本征值由大到小排序，写会到 $\boldsymbol \epsilon$；
3. 假设我们研究的最大体系是 $N$ 个原子，但目前的体系为 $n$ 个原子，那么在方才的 $\boldsymbol \epsilon$ 后面补上 $N-n$ 个零。

返回的是大小为 $N$ 的 $\boldsymbol \epsilon$。

#### Faber *et al.* 的做法

1. 对 CM 矩阵的各个行（或列）求取其 $L_2$ 范数；（这与他们原文 2.4.1 节中的叙述不太一样）
2. 通过范数的大小排序，将各行、各列重新排列；
3. 将第 $n$ 行和 $n$ 列后补上零，直到填充满 $N$ 行列的二维矩阵；
4. 直接对矩阵压平，即将矩阵的各行前后相接。

返回的是大小为 $N^2$ 的向量。

### 补充内容

这个模型是 Faber *et al.* 提到的几种特征处理上，最简单也是结果最差的模型之一。但是这个模型具有下述特征，是一个性质良好的特征工程：
* 化合物空间到 $\mathbf{M}$ 构成的 CM 矩阵空间的映射是单射，且该映射可逆；
* 化合物空间中，若原子可区分，则对称分子的轮换前后的几个分子在 CM 矩阵空间的象唯一；
* CM 矩阵空间中的元素满足正交变换性质：即在原子可区分的化合物空间中，交换若干原子角标将得到两个不同的 $\mathbf{M}$ 矩阵；但这两个矩阵的本征值相同，即可以通过正交变换相互获得；
* CM 矩阵空间中的距离随原子电荷数或原子距离的连续变化是连续的。

这对应到 CM 的向量也是一样的。

后续几种特征工程中，确实平均结果会更好，但有一些工程则不满足上述的一些性质。

关于这里的程序实现，请见 [ReadXYZ.ipynb](https://github.com/ajz34/ML_Course_Code_Report/blob/master/Faber_Code/01-Feature_Vector/ReadXYZ.ipynb) 的 `In [6]` 到 `Out[14]`。

## BoB

### BoB 的特征向量构建

BoB (<u>B</u>ag-<u>o</u>f-<u>B</u>onds) 特征方法的原始文献为 Hansen *et al.* ([JPCL 2015](https://dx.doi.org/10.1021/acs.jpclett.5b00831))。

BoB 实际上仍然使用了 CM 矩阵的数值，但对于如何将矩阵转化为向量，则有另一种处理方法。

![Fig 3. BoB 示意图](/images/Posts/2018-01-30-Faber_Repetition/fig3.png)
<center>
Fig 3. BoB 特征向量提取示意图（摘取自 Hansen <i>et al.</i> (<a href="https://dx.doi.org/10.1021/acs.jpclett.5b00831">JPCL 2015</a>)，Figure 3）<p></p>
</center>

我们从上图乙醇分子进行叙述。

(b) 其实就是一个 CM 矩阵，只是这里用字母对它们进行表示。

(c) 则是最为关键的地方。作者声称，他们从 NLP 中对词语的词性、用途等等进行分类的做法（[Bag-of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model)）中获得灵感，进而将原子类型与键类型作打包处理。现在我们只看 (b) 中上三角的部分。对于原子，我们可以分成氧、碳、氢原子；对于键，我们可以看到有 O-C, O-H, C-H, H-H 键<sup>|2|</sup>。<!--但需要注意到，这些“键”不是化学键，而是一种抽象的模型，只要一个分子里有两个原子，不论这两个原子多远，我们都称它们为键。就譬如这个乙醇分子，并没有两个氢原子真的成了化学键，但 BoB 或者 CM 模型都将它们纳入考虑。-->

这每一个分类，都称为一个 Bag。在每一个 Bag 中，所有的数值都是从 (b) 矩阵白色的部分抽取出来的，并且从大到小排列。这所有的 Bag 中元素的总数加起来应当是 $n(n+1)/2$，如果 $n$ 是目标的原子总数。

打包完毕后，我们希望能将目前的信息储存到一个向量中。(d) 就是在完成这一步。譬如说现在分子集里的分子中，氧原子最多有 $n_\text{O}$ 个，那么对于这个乙醇分子，第 $1$ 位就放入氧原子的 Bag，后面 $n_\text{O}-1$ 位就补零。而碳原子最多有 $n_\text{C}$ 个，那么第 $n_\text{O}+1$ 位开始的两个数放入碳原子的 Bag，后面 $n_\text{C}-2$ 位补零；依此类推。这样，不管是小的分子，还是大的分子，都可以放在相同大小的一维向量中。

当然，实际上未必一定要按照上面的次序把 Bags 组合起来；这种组合本身其实也是比较随意的。不过，通过这种组合方式，我们可以知道，对于通常的分子集，BoB 向量的大小要大于 CM 向量；但每个 BoB 向量的非零数则大约是其对应 CM 向量的 1/2，并且数值上可以对应。

关于这里的程序实现，请见 [ReadXYZ.ipynb](https://github.com/ajz34/ML_Course_Code_Report/blob/master/Faber_Code/01-Feature_Vector/ReadXYZ.ipynb) 的 `In [15]` 到 `Out[25]`。

### BoB 特征存在的问题

#### CM 矩阵单位不统一

这也在 CM 特征中存在，是我在程序实现 BoB 特征向量导出时发现的问题。

在 Faber *et al.* 提供的特征向量文件中，可以发现，CM 特征向量与 BoB 特征向量中，有关于原子的数值大小等值，但关于键的数值却相差 0.529 倍。这是因为 CM 中使用的长度是 Å，而 BoB 中使用的是 a.u.（即 Bohr 半径）。如此的单位差距可能在 Bayesian Regression 中不会体现，毕竟线性模型的参数也可以随着这个单位的转换而缩放；然而像 KRR 中，它主要依靠两个特征向量之间的距离来判定分子之间的相似度，而一个特征向量内不同单位转换会导致的不同相似度结果，这种不同不是简单的缩放。所以我预期这里会出现问题。但这种问题恐怕不会很大，因为键的信息量级是 $n(n-1)/2$，而原子信息的 $n$ 要远小；我们可以粗略地将特征向量近似为只包含键信息的向量，那么两个分子的相似度就随着单位转换而缩放地变化，对结果预期不会有影响。

这部分的推测尚未进行实际计算。

#### BoB 特征空间存在到化学空间的多射

这是在后续文章 Huang and Lilienfeld ([JCP 2016](http://dx.doi.org/10.1063/1.4964627)) 中提出的问题。之所以 BoB 会产生问题，而 CM 没有，是因为 BoB 构成特征向量的时候打乱了键与原子之间的对应。我们可以看下面一张图：

![Fig 4. BoB 问题图](/images/Posts/2018-01-30-Faber_Repetition/fig4.png)
<center>
Fig 4. BoB 多射分子示意图（摘取自 Huang and Lilienfeld (<a href="http://dx.doi.org/10.1063/1.4964627">JCP 2016</a>)，FIG. 1）<p></p>
</center>

现在有四种 Ar<sub>4</sub> 簇，分为 A 与 B 类：

| 簇 | Num. $s$ | Num. $\sqrt{3} s$ | Num. $2 s$ | Num. $\sqrt{5} s$ | Curve |
| - | - | - | - | - | - |
| A<sub>1</sub> | 3 | 3 |  |  | Black |
| A<sub>2</sub> | 3 | 3 |  |  | Blue |
| B<sub>1</sub> | 2 |  | 2 | 2 | Red |
| B<sub>2</sub> | 2 |  | 2 | 2 | Green |

其中 $s$ 为 3.82 Å。注意到 A<sub>2</sub> 是三角锥型的立体结构。既然整个簇只有一种原子，那么它只有两个 Bags：Ar 原子与 Ar 键。因此，容易知道 A、B 类分别的 BoB 特征会是全同的，但显然这全同的 A<sub>1</sub> 与 A<sub>2</sub>，B<sub>1</sub> 与 B<sub>2</sub> 不是同一个分子。

因此作者就尝试看看，这些分子是否会有截然不同的能量表现。在这里的计算模型其实不是量化计算，而仍然是粗略估计——两体作用使用 Lennard-Jones 势，而三体作用使用 Axilrod-Teller-Muto 势。实际情况是，尽管 B<sub>1</sub> 与 B<sub>2</sub> 差别不大，但 A<sub>1</sub> 与 A<sub>2</sub> 相差甚远；这可以从图中黑色与蓝色实线的差别看出来。

这些尝试告诉我们，一个 BoB 特征向量可能对应在化学空间中的分子不只一种；并且这些不同的分子可能表现出截然不同的性质，因此在这个问题上我们不能打马虎眼。可以的话，在未来的实践中需要避免使用这个特征方法。

## BAML

BAML (<u>B</u>onding, <u>A</u>ngular and higher order terms <u>M</u>achine <u>L</u>earning) 特征方法的原始文献为 Huang and Lilienfeld ([JCP 2016](http://dx.doi.org/10.1063/1.4964627))。

这个方法实际上可以看作是 BoB 的升级版。在我的理解中，它仅仅是将 Bags 的范围从原子、键延伸到键角、二面角；同时这些键、角、二面角的信息采用势函数表征。其中的键角、二面角采用 UFF 势；而对于键，则要判断是否为化学键；若是则采用 Morse 势，若否则采用 Lennard-Jones 势。

![Fig 5. BAML 示意图](/images/Posts/2018-01-30-Faber_Repetition/fig5.png)
<center>
Fig 5. BAML 示意图（摘取自 Huang and Lilienfeld (<a href="http://dx.doi.org/10.1063/1.4964627">JCP 2016</a>)，FIG. 1）<p></p>
</center>

可以看到，BoB 与 CM 的计算量不过是上述 $\boldsymbol{\mathrm{M}}^\mathrm{T}$ 中小小的 Atom 与 Bond 的 $n^2$ 而已，而 $\boldsymbol{\mathrm{M}}^\mathrm{T}$ 本身就是 $n^4$ 的量。显然，增大计算量的话就会增加计算精度，但是不是值当就不好说了。作者认为尽管提高的计算精度有限，但意义重大。

## HDAD

HDAD (<u>H</u>istogram of <u>D</u>istance, <u>A</u>ngles, <u>D</u>ihedral angles) 方法，或者其弱化版本 HD 方法，应该是 Faber *et al.* 文章本身提出的方法。

我认为，它可以基于 BAML 理解。之前，我们对键、键角与二面角进行势函数预处理，并进行分类打包，因而会得到相对较好的结果。然而，特征向量本身的长度还在那里，它的计算量仍然很大。为此，作者再一次进行打包——这次是将数据进行打包并离散化。在一个 Bag 内，将相近的数据归到相同的离散数值区间 Bin 中，而距离较远的数据归到不同的数值；每一类 Bag 设置数量不等的这样的 Bins。

就像下面图所示，对于 C-N 键而言，如果键长大于 10 Å，那么我们认为这些键再长，也跟 10 Å 的键没有差别；而键长在 8.5 - 10 Å 的键，我们也近似认为这些键对分子性质的贡献等价从而归为一类。最后，我们可以这样表述分子：在 C-N Bag 中，键长大于 10 Å 的 Bin 的总数为……个，而在 8.5 - 10 Å 的 Bin 的总数为……个。计数结果就可以作为特征向量，输入到 ML 中进行训练。HDAD 方法也不需要进行势函数的预处理。

![Fig 6. HDAD 示意图](/images/Posts/2018-01-30-Faber_Repetition/fig6.png)
<center>
Fig 6. HDAD 部分 Bag 下的 Bin 拆分示意图（摘取自 Faber *et al.* (<a href="http://dx.doi.org/10.1021/acs.jctc.7b00577">JCTC 2017</a>)，Figure 1）<p></p>
</center>

但是刚刚并没有提到如何拆出这些 Bins。这个过程是实际上通过手动的方式进行的。作者首先对 QM9 数据集的分子进行每个键种的键长、键角或二面角数值的分布图（即上图）；随后手动地对这幅图进行 Bin 拆分。图上的一根根线就是 Bin 区间的分界线。一般来说，拆分分界线在分布图的低洼处，不过显然许多处并没有按这个原则划分。

因为这个方法对分子信息作了离散化，因此，它应当是一个不随原子连续的微扰移动而导出连续变化的性质的方法。

## ECFP_4

ECFP (<u>E</u>xtended <u>C</u>onnectivity <u>F</u>inger<u>p</u>rints) 分子编码方法的原始文献为 Rogers and Hahn ([JCIM 2010](http://dx.doi.org/10.1021/ci100050t))。

这个方法本身的目的应该是对分子进行尽可能高压但有效的编码。它的编码原则有很多也很复杂，但大体来说，就是先对每一个原子提取其特征进行编码；随后对于每一个原子，使用其相邻原子的信息对它产生扰动，生成一个新的编码；如此反复进行 $n$ 次。最后，将先前产生过的所有原子编码收集起来，剔除其中不合规的以及重复的编码，得到最终的 ECFP_$n$ 分子编码。在这个例子中，$n=4$。

下图是 ECFP 方法用来举例子的分子，它将告诉我们，$n=4$ 代表了被编码原子可以看到的化学环境大小。

![Fig 7. ECFP 示意图](/images/Posts/2018-01-30-Faber_Repetition/fig7.png)
<center>
Fig 7. ECFP 对硝基苯 1 号原子迭代编码示意图（摘取自 Rogers and Hahn (<a href="http://dx.doi.org/10.1021/ci100050t">[JCIM 2010</a>)，Figure 2）<p></p>
</center>

对于上述硝基苯的 1 号原子，我们在预编码的时候，只考虑碳原子本身、以及它身上所拥有的三根键的种类（芳香、芳香与单键）的信息；因此这个编码包含了 1 号原子与其周围一层化学环境信息。而第一次编码中，1 号原子会将 6, 7, 8 号原子的信息编入 1 号原子；而 6, 7, 8 号原子在编码的时候已经预编入了它们相邻的化学环境信息，因此第一次编码后的 1 号原子将包含了其周围两层化学环境信息。第二次编码同样，可以得到周围三层的化学环境信息。因此，对于 1 号原子，三次迭代编码就足够充分了。

这种编码可能的问题会是，首先，编码可能带来有损压缩；其次，既然 ECFP_$n$ 的 $n$ 代表被编码分子的原子能看到的化学环境，那么如果 $n$ 太小，那么很可能在解码的时候回产生若干个局部结构非常相似但整体结构完全不同的分子。

Faber *et al.* 尝试将这种编码使用在 ML 中，结果显然是不好的。我认为这可能可以用下述的原因解释：
1. ECFP 编码方式本身就是非物理的编码。或者说它缺少了类似于 BoB 对键长的 Coulomb 斥力或势函数的预处理一步。
2. ECFP 构建出来的是一个纯粹的分子结构式，而不是一个三维的分子。因此，键长、键角、原子坐标等信息是彻底缺失的。不应该预期它的结果比 CM 好。
3. 同时，既然一个良好的方法应当能通过分子的坐标就得到分子的各种性质，而不应该对目标分子用、或者不应该加以键级与键连关系来描述。如果我们现在想要用 ML 画一个分子解离的势能曲线，显然 ECFP 的特征向量是不适用的。

## 对于特征工程的补充

文中还补充了 MARAD 方法。这个方法应该也是 Faber *et al.* 新提出的方法。然而我现在还未能理解这个方法。

对于深度学习模型（特别是以图模型为基础的深度学习模型），其特征设计思路与上述的方法完全不同：之所以使用这类模型，就是因为分子可以表示为图、原子可以看作节点（vertex）、而键可以看作边（edge）。因此，设计特征输入的时候，也应该遵循这个原则，即生成每一个原子的特征向量作为节点特征、生成每一个键的特征向量作为边的特征；除此以外的信息是不必要的。

因此，深度学习模型的特征设计现在恐怕无法做得很复杂。现在能考虑到的无非是（摘自 Gilmer *et al.* ([ICML 2017](http://proceedings.mlr.press/v70/gilmer17a.html))，第 6 节）
* 原子：原子种类、原子序号、价层供电子数、价层得电子数、是否处于芳环、杂化形式、配位氢原子数等；
* 分子：键长、键级等。
因此，我想深度学习拟合分子的化学性质的主要挑战仍然是算法的设计上。（化学发展了这么多年，有了这么多定性化学理论，结果还不是原子和键长就解决了问题？）

不论是在 Faber *et al.* 还是在 Gilmer *et al.* 上，目前表现最优异的方法都是深度学习方法。因此，我很难说我会认为上面花了大力气写的几种特征方法在将来还会起到重要的作用。不过，这条路径我希望不会是无意义的。在 BoB 的原始文献 Hansen *et al.* ([JPCL 2015](https://dx.doi.org/10.1021/acs.jpclett.5b00831)) 上，他们不仅讨论了原子种类与键种类打包的问题，还讨论了键的势能问题。他们通过多项式拟合的方法，得到 GDB-7 分子集平均的 C-C 势能对键长的势函数，验证了它与 Lennard-Jones 势函数非常相似。因此，我们可以说粗略的情况下，用 Lennard-Jones 势函数表示原子的解离或者得出分子的能量确实是合理的；并且指导了后续的几种特征工程的键长处理方式。我想这样一篇文章会是很有意思的。

# 评价

免责声明：这一节是大话吹笔时间。就当这是借酒劲写的胡话（事实也是如此）。（认真脸 = =）

对我来说，正因为用 ML 作拟合得到分子性质是一个比较容易被攻击的问题，因此会作此感慨。下面的感慨倒与上面的叙述无大关联。

## 关于拟合 DFT 的感想

我曾经一位室友是药学-有机方向。我问过他，说如果现在有两种 DFT，
1. 一种比较接近真实泛函（我们不妨假定真实泛函存在可以套用到 Kohn-Sham 解的简单形式），它算啥都不差，但也不算太准；
2. 另一种偏离真实泛函比较远，但它算药物分子的结果会更好；

两个计算代价啊啥的都一样。你要哪一种？

他当然毫不犹豫地选后面一个。

现在我能了解到的情况是，类似于 PBE 的更接近于真实的泛函在化学中未必比 M06 系列泛函更受到欢迎<sup>|2|</sup><!--注释：对于这里的“更接近于”，不同的人显然会有不同的评价方式。这里引用的是 Predew 等人的评述方式（Medvedev *et al.*, [Science 2017](https://dx.doi.org/10.1126/science.aah5975)）。Predew 的著名工作之一是开发无经验参数泛函，这些泛函相对于其它流行 DFT 近似而言通常会满足更多泛函限制条件。在前述链接文章中，作者的数据表明 M06 系列泛函尽管能量表现不错，但电子密度表现并不太好；是偏离真实泛函的表现之一。-->。M06 系列泛函不算是很准确的泛函；之所以其表现良好，可能主要的原因是其开发原理与大多数泛函不太一样。它的泛函中有大量参数（约 50 个），这些参数由实验数据进行拟合，而拟合范围是大量的化学分子与反应。因此，泛函在这些分子、这类反应下的表现通常都好于其它泛函不少；而化学家最关心的大多也就在这些分子、这类反应之间。而 PBE 泛函则是物理与化学领域中都使用的泛函，满足了更多的泛函限制条件，看起来更接近真实泛函；但计算结果却经常劣势于 M06 系列。

我作为理论化学的学生，也许会理所当然地认为，第 1 条路径更好。即使使用类似于 PBE 的泛函会牺牲一些计算准确度，但我们可以一步一步地对泛函引入限制条件来改善泛函，使得这个泛函也可以越来越准确——既然 Schrödinger 方程原则上能被无穷精度地求解，这种泛函也应当存在。而反过来说，用一个有大量参数，但模型本身较为一般的泛函形式进行拟合，不是一个很好的途径——毕竟拟合过程中，泛函模型误差也许不大，但被拟合的数据本身也有着误差；这两个误差叠加也许凑巧得到不错的结果，但这两个误差都是难以从理论上修正的，并且作为误差还有叠加的可能。这是为什么我也许会觉得，开发新泛函的思路最好是能沿着泛函限制条件。

但是第 2 条路径相信是更为大家接受的。毕竟，在可见的未来，在相同的计算量下，第 2 类泛函即使会受到批评，但其实对于我们关心的分子表现稳定且良好，我们为何不用呢？

这个问题看起来跟这篇文章没有关系，但是我认为如果接受第 2 条路径的人，不妨考虑一下 ML 的结果。

## 直接 ML 计算化学性质的感想

在 DFT 上套以 ML，我了解的是现在至少有两种策略。一种是直接用 ML 做泛函（Brockherde *et al.*, [*Nat. Commun.* 2017](https://dx.doi.org/10.1038/s41467-017-00839-3)），另一种就是这篇文章的做法，即将 DFT 结果用 ML 拟合。这里讲的是后一种。至于是否使用深度网络，还是使用较为原始的机器学习，在讨论当前这个问题上不是很重要。

如果我选择了上面一节提到的第 2 条路径，作为化学工作者，我想我一定会犹豫着是否要用 ML 替代 DFT 计算。DFT 显然是由学界所承认的方法，尽管其计算量很大，作为模型的精度也未必好于拟合区间里的 ML。DFT 之所以被学界所承认，我想是因为它具有清楚的物理意义，有 Hohenberg-Kohn 定理托底；而这是 ML 所不具备的。

举一个很不恰当的例子。如果现在有一段动画，想要表达钢琴家（Kousei）与小提琴家（Kaori）激情澎湃的表演；然而制作公司（A-1 Pictures）没有足够经费（chéngyì）充分表现这个镜头。最中规中矩的方式是仍然绘制两人的动图，但会把手部动作切掉不很多，只留下头部的陶醉神情；另一种则是突破常规，在很少的几秒之内充分绘制手部动作，但剩下的几秒用静止立绘（PPT）替代。两种都不完美，但也可以一定程度地让观众感受到动画的魅力。我觉得 DFT 近似更像前者，而 ML 更像后者。

（我觉得我要被四月迷寄刀片了 ↗﹏↖ 况且 Sony 亲儿子；外加作为不懂动画的人，上面的话多少有些曲解监督分镜的初衷）

回到话题。DFT 本身有物理含义，但如果一些 DFT 近似却舍弃了大部分物理含义给它的限制，那么我们就不应当认为这种 DFT 是基于物理的，而是基于工业应用的。这与 ML 解决化学性质问题几乎是一致的，只是两者的模型名称不同而已。我们其实不必拘泥于 DFT 近似的模型而直接使用更高效而不失效率的 ML；就像几张漂亮的立绘和几秒华丽的动画就可以达到甚至超脱于平平凡凡的动作，为何不用？

## 对于 DFT 近似未来的担忧

可能在很长一段时间里，ML 无法比 DFT 近似更好。毕竟拟合集的误差在那里，外加 ML 方法解决本应可以用有严格物理基础的化学问题恐怕会在短期内不为大家很快接受；但这恐怕是暂时的。拟合集误差只会越来越小，ML 模型误差只会越来越小；这种情况下，再顽固的人都会动摇。那么我们是否要继续研究 DFT 呢？

研究 DFT 也许会有两种目的，效率与理论本身的意义。

DFT 本身就是作为与 HF 计算量级相同，但要远适合现实计算的理论基础。如今大多数中等体系都已经接受了 DFT 计算量，所以 DFT 才会走入大家的视野。

然而绝大多数 DFT 近似都使用了经验参数的拟合，或多或少。即使是无经验参数的 DFT 近似，它也多少包含一些设计上经验的考虑。如果我们把 DFT 近似当作一种模型原理，这和 ML 有什么区别？只是 DFT 近似的泛函集不需要很多，只要构造比较合理，寥寥几个参数就可以得到一个不错的泛函；ML 则是少则几百，多则上万的参数，但还是算得快。在将来，如果无视了分子计算中的容斥规则的话，甚至可以让 ML 的计算量线性地随分子大小而增大（就如 [Gilmer *et al.*](http://proceedings.mlr.press/v70/gilmer17a.html) 文中所述的 Tower8 方法，也许用几个神经网络将分立的隐含层接起来就可以降低计算量）。在这个时代，哪个会发展得更好，一目了然。为了计算精度而设计的 DFT 近似恐怕会陷入困境。

但是如果将 DFT 当作理论来看的话，就会看到另一种风景。最近的一份工作中（Su *et al.*, [PNAS 2018](https://dx.doi.org/10.1073/pnas.1713047115)），作者提到了一类引入虚轨道的非自洽 DFT 近似（xDH）在一些原子与离子的能量与密度性质结果均好于<u>所有</u>杂化泛函。从我的角度和我现在的理解来看，尽管这类泛函大多也有经验参数的成分，但是它对 DFT 近似的模型的改变和结果的优势已经足以让我们去关注后面可能发掘这种模型的物理含义；并且这种认识有希望帮助我们对于我们的目标——终极的泛函的理解更加接近于真实。

不过既然我觉得，尽管 DFT 曾经在千禧年前后有巨大的发展，将来的 DFT 理论学者可能随着 DFT 近似的衰弱而越来越孤独。即使如此，我想 Hohenberg-Kohn 会很开心——我相信他们一开始没有觉得这个理论会如此有生命力。我也觉得如果我们看到了他们无法看到的精确泛函，他们一定在天堂吓一跳。

# 注释

| 1 |

对于这里的“更接近于”，不同的人显然会有不同的评价方式。这里引用的是 Predew 等人的评述方式（Medvedev *et al.*, [Science 2017](https://dx.doi.org/10.1126/science.aah5975)）。Predew 的著名工作之一是开发无经验参数泛函，这些泛函相对于其它流行 DFT 近似而言通常会满足更多泛函限制条件。在前述链接文章中，作者的数据表明 M06 系列泛函尽管能量表现不错，但电子密度表现并不太好；是偏离真实泛函的表现之一。

| 2 |

但需要注意到，这些“键”不是化学键，而是一种抽象的模型，只要一个分子里有两个原子，不论这两个原子多远，我们都称它们为键。就譬如这个乙醇分子，并没有两个氢原子真的成了化学键，但 BoB 或者 CM 模型都将它们纳入考虑。

# 未尽

1. 这篇博文不管是工作，还是观点，大多数都是独立完成；因此希望大家如果看到不合适的说辞，不要联想到其他人。

2. 在上这门课之前，我算是不会 Python，不懂机器学习的人；对于 DFT 近似其实是一知半解，Python 之前只用过 FORTRAN。说实话还有太多的东西没有学习。大家可以批评我的懒惰，但希望在对术语或概念的理解上，稍稍宽容一些。

3. 这门课程大约占用平时学习时间的约 1/3，这包括了其它课程、以及在课题组工作的时间。说实话这个学期在课题上没有很好的进展。因此非常感谢导师对我在这段时间的宽容。也感谢老师、师兄弟（姐妹）的这段时间的鼓励、支持和批评。之后恐怕会很少再碰这个话题，但我还是想持续关注。当然，如果不是这门课程，我想以我半吊子的性格，不会想尝试认真地对待这个或许很新的领域；因此我也很感谢能上到这门课。

4. 正因为目前不会使用 TensorFlow，现在能做的重复工作也不超过这篇文章了。我会在可能的情况下再尽力尝试重复 Gilmer *et al.* ([ICML 2017](http://proceedings.mlr.press/v70/gilmer17a.html)) 的文章。最近看到的与这篇文章相关的代码是在 [Microsoft/gated-graph-neural-network-samples](https://github.com/Microsoft/gated-graph-neural-network-samples)，此代码现在仍然在活跃地更新，但我认为这份代码没有真正直接地重复 Gilmer *et al.* 的文章。希望大家能期待我下一篇此话题的博客。

# 改动日志

* 2018-01-30 创建网页（占坑）
* 2018-02-15 初次更新，未公开
* 2018-02-16 公开初稿
